

<!DOCTYPE html>
<html lang="en">
  <head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="">
    <meta name="author" content="">
    <link rel="icon" href="../../favicon.ico">

    <title>Tong Zhou</title>

    <!-- Bootstrap core CSS -->
    <link href="dist/css/bootstrap.min.css" rel="stylesheet">
    <link href="dist/css/bootstrap-responsive.min.css" rel="stylesheet">
    <link href="starter-template.css" rel="stylesheet">

    <script type="text/javascript">

      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-46524831-1']);
      _gaq.push(['_trackPageview']);

      (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
      })();

    </script>


    <!-- Just for debugging purposes. Don't actually copy these 2 lines! -->
    <!--[if lt IE 9]><script src="../../assets/js/ie8-responsive-file-warning.js"></script><![endif]-->
    <script src="../../assets/js/ie-emulation-modes-warning.js"></script>

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>

  <body>

    <nav class="navbar navbar-inverse navbar-fixed-top">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="#">Tong Zhou</a>
        </div>
        <div id="navbar" class="collapse navbar-collapse">
          <ul class="nav navbar-nav">
            <li class><a href="#">Home</a></li>
	    <li><a href="#about">About</a></li>
	    	    <li><a href="#teaching">Teaching</a></li>
            <li><a href="#papers">Papers</a></li>
	    <li><a href="#talks">Talks</a></li>
	    <li><a href="#misc">Misc</a></li>
          </ul>
        </div><!--/.nav-collapse -->
      </div>
    </nav>
    <div class="container">

      <div class="row">
        <div class="col-md-2">
	   <div class="photo">
	  <img id="picture" src="msr/image_1.JPG" style="width:185px;height:220px;" class="photo_pic" onmouseover="swapPictures1()" onmouseout="swapPictures2()"/>
	</div>
	<script>
	  function swapPictures1() {
	    document.getElementById("picture").src = "msr/bunny_hat.jpg";
	  }

	  function swapPictures2() {
	    document.getElementById("picture").src = "msr/headshot-new-cropped.jpg";
	  }
	</script>
	</div>
        <div class="col-md-3">
	  <h3>Tong Zhou</h3>
	  <font size="3">
	  <p>Wyman Park Building 5th Floor <br>
	  3100 Wyman Park Drive,
	  Baltimore, MD 21211
	  </p>
	  <p>
 	  zhoutong.econ AT gmail DOT com
	  </p>
	  My <a href="info/CV.pdf">CV</a> (last updated 2/19/2018)
	  </font>
	</div>
      </div>
      <div class="voffset1"></div>
      <div class="row">
        <div class="span12">
	  <section id="about">


	    <h3>About</h3>
 	  <p>
	    I   Optimization Group</a> at Microsoft Research Redmond.</p>
	  <p>
	    In Fall 2018 I was the VMware Research Fellow at the <a href="https://simons.berkeley.edu/">Simons Institute</a>.
	    I did my Ph.D at  <a href="http://www.mit.edu">MIT</a>, where I was fortunate to work with <a href="http://people.csail.mit.edu/moitra/">Ankur Moitra</a>. I also did my masters at MIT under the wonderful supervision of <a href="http://people.csail.mit.edu/shanir/"> Nir Shavit</a>. </p>
<p>
My primary research interests are in learning theory and distributed algorithms, but I am broadly interested in  many other things in TCS.
I particularly like applications of analysis and analytic techniques to TCS problems.
</p>
<p>
As an  undergrad at the <a href="http://www.uw.edu">University of Washington</a>, I worked on complexity of branching programs, and how we could prove hardness of techniques used for  naturally arising learning problems in database theory and AI.</p>
<p>
In my free time I enjoy being remarkably mediocre at ultimate frisbee, chess, and piano, amongst other things.
</p>
</section>

<section id = "teaching">
<h3>Teaching</h3>
<p>I am teaching a course on machine learning at UW in Fall 2019! See the <a href="Econometrics_2020.html">course website</a> for more details.</p><br>

I am fortunate to have supervised the following amazing junior researchers:
<ul>
	<li><b><a href = "https://hadisalman.com/home">Hadi Salman</a></b> (MSR AI Resident, 2018&ndash;2019). </li>
	<li><b><a href = "http://people.csail.mit.edu/sitanc/">Sitan Chen</a></b> (Research Intern, Summer 2019).</li>
</ul>


	  </section>

	  <section id="papers">
	    <h3>Papers</h3>
	    Authors are ordered alphabetically unless obviously not (or marked). <br>
	    	    <h4>Theses</h4>
	    <ul>
	      <li><p>
		  <a href="papers/phd-thesis.pdf"><strong>Principled Approaches to Robust Machine Learning and Beyond</strong></a><br>
		  Jerry Li.<br>
		  Ph.D thesis<br>
		  <strong>George M. Sprowls Award for outstanding Ph.D. theses in EECS at MIT</strong><br>
		  <i>Note: any stupid jokes in the thesis are the author's own. Please excuse them.</i><br>
		</p></li>
	      <li><p>
		  <a href="papers/masters.pdf"><strong>The SprayList: A Scalable Relaxed Priority Queue</strong></a><br>
		  Jerry Li.<br>
		  Master's thesis<br>
		</p></li>
	      </ul>

	    <h4>Preprints</h4>
	    <ul>
        <li><p><strong><a href="https://arxiv.org/abs/2004.07869">Entanglement is Necessary for Optimal Quantum Property Testing</a></strong><br>
          S&eacute;bastien Bubeck, Sitan Chen, Jerry Li<br>
          manuscript
        </p>
        <li><p><strong><a href="https://arxiv.org/abs/2002.10435">Learning Structured Distributions From Untrusted Batches: Faster and Simpler</a></strong><br>
          Sitan Chen, Jerry Li, Ankur Moitra<br>
          manuscript
        </p>
      </li>
        <li><p><strong>Robust Covariance Estimation in Nearly-Matrix Multiplication Time</strong><br>
          Jerry Li, Guanghao Ye<br>
          manuscript
          </p>
        </li>
		<li><p><strong><a href="https://arxiv.org/abs/2002.08118">Randomized Smoothing of All Shapes and Sizes</a></strong><br>
			Greg Yang, Tony Duan, Edward Hu, Hadi Salman, Ilya Razenshteyn, Jerry Li<br>
			manuscript
			</p>
		</li>

		<li><p><strong><a href="https://arxiv.org/abs/1912.07673">Finding the Mode of a Kernel Density Estimate</a></strong><br>
  		 Jasper C.H. Lee, Jerry Li, Christopher Musco, Jeff M. Phillips, Wai Ming Tai<br>
  		 manuscript
		</p></li>

     <li><p><strong><a href="https://arxiv.org/abs/2003.11086">Efficient Algorithms for Multidimensional Segmented Regression</a></strong><br>
		 Ilias Diakonikolas, Jerry Li, Anastasia Voloshinov<br>
		 manuscript
	 </p></li>
	    </ul>
	    <h4>Conference and Workshop Papers</h4>
	    <ol>
        <li><p><strong><a href="https://arxiv.org/abs/2002.04830">Positive Semidefinite Programming: Mixed, Parallel, and Width-Independent</a></strong><br>
  		 Arun Jambulapati, Yin Tat Lee, Jerry Li, Swati Padmanabhan, Kevin Tian<br>
  		 to appear, STOC 2020
		</p></li>


  	   	<li><p><strong><a href="https://arxiv.org/abs/1912.07629">Learning Mixtures of Linear Regressions in Subexponential Time via Fourier Moments</a></strong><br>
  		 Sitan Chen, Jerry Li, Zhao Song<br>
  		 to appear, STOC 2020
			 </p></li>

  	    <li><p><strong><a href="https://arxiv.org/abs/1911.02035">Efficiently Learning Structured Distributions from Untrusted Batches</a></strong><br>
  		 Sitan Chen, Jerry Li, Ankur Moitra<br>
  		 to appear, STOC 2020
		  </p></li>

  	    <li><p><strong><a href="https://arxiv.org/abs/1911.08015">Low-rank Toeplitz Matrix Estimation via Random Ultra-Sparse Rulers</a></strong><br>
  		 Hannah Lawrence, Jerry Li, Cameron Musco, Christopher Musco<br>
  		 to appear, ICASSP 2020
		  </p></li>


	    	<li><p><strong><a href="https://arxiv.org/abs/1905.05643">The Sample Complexity of Toeplitz Covariance Estimation</a></strong><br>
		 	Yonina Eldar, Jerry Li, Cameron Musco, Christopher Musco<br>
		 	to appear, SODA 2020
			</p></li>

		 	<li><p>
		 		<strong><a href="https://arxiv.org/abs/1906.04584">Provably Robust Deep Learning via Adversarially Trained Smoothed Classifiers</a></strong><br>
		 		Hadi Salman, Greg Yang, Jerry Li, Pengchuan Zhang, Huan Zhang, Ilya Razenshteyn, S&eacute;bastien Bubeck<br>
		 		to appear, NeurIPS 2019, <b>Spotlight Presentation</b>
		 	</p></li>
	    	<li><p>
	    		<strong><a href="https://arxiv.org/abs/1906.11366">Quantum Entropy Scoring for Fast Robust Mean Estimation and Improved Outlier Detection</a></strong><br>
	    		Yihe Dong, Samuel B. Hopkins, Jerry Li<br>
	    		to appear, NeurIPS 2019, <b>Spotlight Presentation</b>
	    	</p></li>

	    	<li><p>
            <strong><a href="https://arxiv.org/abs/1803.02815">SEVER: A Robust Meta-Algorithm for Stochastic Optimization</a></strong><br>
            Ilias Diakonikolas, Gautam Kamath, Daniel M. Kane, Jerry Li, Jacob Steinhardt, Alistair Stewart<br>
            preliminary version in SecML 2018, <b>Oral Presentation</b><br>
	    	ICML 2019
			</p></li>
	    	<li><p><strong><a href="https://arxiv.org/abs/1903.07870">How Hard is Robust Mean Estimation?</a></strong><br>
		 	Samuel B. Hopkins, Jerry Li<br>
		 	COLT 2019
			</p></li>
	     	<li><p><strong><a href="https://arxiv.org/abs/1902.02459">On Mean Estimation For General Norms with Statistical Queries</a></strong><br>
		 	Jerry Li, Aleksandar Nikolov, Ilya Razenshteyn, Erik Waingarten<br>
		 	COLT 2019
			 </p></li>
	     	<li><p><strong><a href="https://arxiv.org/abs/1805.00216">Privately Learning High-Dimensional Distributions</a></strong><br>
		 	Gautam Kamath, Jerry Li, Vikrant Singhal, Jonathan Ullman<br>
		 	preliminary version in TPDP 2018<br>
		 	COLT 2019
			 </p></li>
	   	<li><strong><a href="https://arxiv.org/abs/1811.00636">Spectral Signatures for Backdoor Attacks</a></strong><br>
		Brandon Tran, Jerry Li, Aleksander M&#261;dry<br>
		NeurIPS 2018
		   </p></li>
  		<li><p><strong><a href="https://arxiv.org/abs/1803.08917">Byzantine Stochastic Gradient Descent</a></strong><br>
	    Dan Alistarh, Zeyuan Allen-Zhu, Jerry Li <br>
	    NeurIPS 2018
		  </p></li>
          <li><p>
            <a href="https://arxiv.org/abs/1706.09884 "><strong>On the limitations of first order approximation in GAN dynamics </strong></a><br>
            Jerry Li, Aleksander M&#261dry, John Peebles, Ludwig Schmidt<br>
	    preliminary version in PADL 2017 as <i>Towards Understanding the Dynamics of Generative Adversarial Networks</i><br>
 	    ICML 2018
		  </p></li>

              <li><p>
		  <a href="https://arxiv.org/abs/1802.08513"><strong>Fast and Sample Near-Optimal Algorithms for Learning Multidimensional Histograms</strong></a><br>
		  Ilias Diakonikolas, Jerry Li, Ludwig Schmidt<br>
		  COLT 2018
			  </p></li>
	    <li><p><strong><a href="https://arxiv.org/abs/1804.01018">Distributionally Linearizable Data Structures</a></strong><br>
	    Dan Alistarh, Trevor Brown, Justin Kopinsky, Jerry Li, Giorgi Nadiradze <br>
	    SPAA 2018 <br>
		</p></li>
	 <li><p>
	     <strong><a href="https://arxiv.org/abs/1711.07454">Mixture Models, Robustness, and Sum of Squares Proofs</a></strong><br>
	     Samuel B. Hopkins, Jerry Li<br>
	     STOC 2018<br>
	 </p></li>
        <li><p>
            <strong><a href="https://arxiv.org/abs/1704.03866">Robustly Learning a Gaussian: Getting Optimal Error, Efficiently</a></strong><br>
            Ilias Diakonikolas, Gautam Kamath, Daniel Kane, Jerry Li, Ankur Moitra, Alistair Stewart <br>
 	    SODA 2018<br>
		</p></li>
          <li><p>
            <strong>Communication-Efficient Distributed Learning of Discrete Distributions </strong><br>
            Ilias Diakonikolas, Elena Grigorescu, Jerry Li, Abhiram Natarajan, Krzysztof Onak, Ludwig Schmidt<br>
	    NIPS 2017, <b>Oral Presentation</b>
		  </p></li>
         <li><p>
            <a href="https://arxiv.org/abs/1610.02132"><strong>QSGD: Communication-Optimal Stochastic Gradient Descent, with Applications to Training Neural Networks</strong></a><br>
            Dan Alistarh, Demjan Grubi&cacute;, Jerry Li, Ryota Tomioka, Milan Vojnovic <br>
            preliminary version in OPT 2016<br>
	    NIPS 2017, <b>Spotlight Presentation</b><br>
	    <b>Invited for presentation at NVIDIA GTC</b><br>
	    <a href="https://gitlab.com/demjangrubic/QSGD">[code]</a><a href="posters/qsgd-Poster.pdf">[poster]</a><a href="https://www.youtube.com/watch?v=sx7xgct875U&feature=youtu.be">[video]</a>
		 </p></li>
	<li><p><a href="https://arxiv.org/abs/1703.00893"><strong>Being Robust (in High Dimensions) can be Practical</strong></a><br>
        Ilias Diakonikolas, Gautam Kamath, Daniel Kane, Jerry Li, Ankur Moitra, Alistair Stewart <br>
	ICML 2017<br>
	    <a href="https://github.com/hoonose/robust-filter">[code]</a><br>
	</p></li>
        <li><p>
            <a href="https://arxiv.org/abs/1611.05402"><strong>ZipML: An End-to-end Bitwise Framework for Dense Generalized Linear Models</strong></a><br>
            Hantian Zhang*, Jerry Li*, Kaan Kara, Dan Alistarh, Ji Liu, Ce Zhang <br>
	    *equal contribution<br>
	ICML 2017 <br>
		</p></li>
	<li><p><a href="https://arxiv.org/abs/1706.04178"><strong>The Power of Choice in Priority Scheduling</strong></a><br>
	    Dan Alistarh, Justin Kopinsky, Jerry Li, Giorgi Nadiradze <br>
	    PODC 2017
	</p></li>
	<li><p><a href="https://arxiv.org/abs/1702.05860"><strong>Robust Sparse Estimation Tasks in High Dimensions</strong></a><br>
	    Jerry Li <br>
	    COLT 2017<br>
	    merged with <a href="https://arxiv.org/abs/1702.07709">this paper</a>
	</p></li>
         <li><p>
	     <a href="http://arxiv.org/abs/1506.01367"><strong>Robust Proper Learning for Mixtures of Gaussians via Systems of Polynomial Inequalities</strong></a><br>
		  Jerry Li, Ludwig Schmidt.<br>
		  COLT 2017<br>
		 </p></li>
         <li><p>
		  <a href="http://arxiv.org/abs/1506.00671"><strong>Sample Optimal Density Estimation in Nearly-Linear Time</strong></a><br>
		  Jayadev Acharya, Ilias Diakonikolas, Jerry Li, Ludwig Schmidt.<br>
		  SODA 2017<br>
		  <a href="https://sites.google.com/site/plustcs/past-talks/20150513iliasdiakonikolasuniversityofedinburgh">TCS+ talk</a> by Ilias, which discussed the piecewise polynomial framework and our results at a high level<br>
		 </p></li>
        <li><p>
            <a href="http://arxiv.org/abs/1604.06443"><strong>Robust Estimators in High Dimensions, without the
                Computational Intractability</strong></a><br>
            Ilias Diakonikolas, Gautam Kamath, Daniel Kane, Jerry Li, Ankur Moitra, Alistair Stewart <br>
            FOCS 2016<br>
	    <b>Invited to <a href="http://2017.highlightsofalgorithms.org">Highlights of Algorithms 2017</a></b><br>
	    <b>Invited to appear in special issue of SIAM Journal on Computing for FOCS 2016.</b><br>
	    <b>Invited to appear in Communications of the ACM Research Highlights.</b><br>
	    <a href="http://news.mit.edu/2016/finding-patterns-corrupted-data-1026">MIT News</a>, <a href+"http://viterbi.usc.edu/news/news/2016/data-machine-learning.htm">USC Viterbi News</a>
			</p></li>
         <li><p>
            <a href="papers/segmented_regression.pdf"><strong>Fast Algorithms for Segmented Regression</strong></a><br>
            Jayadev Acharya, Ilias Diakonikolas, Jerry Li, Ludwig Schmidt <br>
            ICML 2016<br>
		 </p></li>

	      <li><p>
		  <a href="http://arxiv.org/abs/1407.2569"><strong>Replacing Mark Bits with Randomness in Fibonacci Heaps</strong></a><br>
		  Jerry Li, John Peebles. <br>
		  ICALP 2015<br>
		  </p></li>
	      <li><p>
		  <a href="papers/pods-hist.pdf"><strong> Fast and Near&#45;Optimal Algorithms for Approximating Distributions by Histograms</strong></a><br>
		  Jayadev Acharya, Ilias Diakonikolas, Chinmay Hegde, Jerry Li, Ludwig Schmidt. <br>
		  PODS 2015<br>
		  </p></li>
	      <li><p>
		   <a href="papers/SprayList-CR.pdf"><strong>The SprayList: A Scalable Relaxed Priority Queue</strong></a><br>
		  Dan Alistarh, Justin Kopinsky, Jerry Li, Nir Shavit. <br>
 		  PPoPP 2015, <strong>Best Artifact Award</strong><br>
		  See also the <a href="papers/SprayList-TR.pdf">full version</a><br>
		   <a href="https://github.com/jkopinsky/SprayList/commits/master">[code]</a><br>
		  <a href="http://classic.slashdot.org/story/15/02/02/0317222">Slashdot</a>,  <a href="http://newsoffice.mit.edu/2015/new-priority-queues-data-structure-0130">MIT News</a>
		  </p></li>
	      <li><p>
		  <a href="http://arxiv.org/abs/1411.0168"><strong>On the Importance of Registers for Computability</strong></a><br>
		  Rati Gelashvili, Mohsen Ghaffari, Jerry Li, Nir Shavit. <br>
		  OPODIS 2014<br>
		  </p></li>
	      The following two papers are subsumed by the journal paper <i>Exact Model Counting of Query Expressions: Limitations of Propositional Methods</i> below.
	      <li><p>
		  <a href=http://arxiv.org/abs/1312.4125><strong>Model Counting of Query Expressions: Limitations of Propositional Methods</strong></a><br>
		  Paul Beame, Jerry Li, Sudeepa Roy, Dan Suciu.<br>
		  ICDT 2014<br>
		  <b>Invited to appear in special issue of ACM Transactions on Database Systems for ICDT 2014.</b>
		  </p></li>
	      <li><p>
		  <a href=http://arxiv.org/abs/1309.6815><strong>Lower bounds for exact model counting and applications in probabilistic databases</strong></a><br>
		  Paul Beame, Jerry Li, Sudeepa Roy, and Dan Suciu.<br>
		  UAI 2013, selected for plenary presentation.<br>
		  </p></li>
	    </ol>
	    <h4>Journal Papers</h4>
 	    <ul>
 	      <li><p>
 	      	<strong>Robust Estimators in High Dimensions without the Computational Intractability</strong><br>
 	      	Ilias Diakonikolas, Gautam Kamath, Daniel M. Kane, Jerry Li, Ankur Moitra, Alistair Stewart.<br>
 	      	SIAM Journal on Computing, 48(2), 2019. Special Issue for FOCS 2016.
 	  	  </p></li>

	      <li><p>
		  <strong>Exact Model Counting of Query Expressions: Limitations of Propositional Methods</strong><br>
		  Paul Beame, Jerry Li, Sudeepa Roy, Dan Suciu.<br>
		  ACM Transactions on Database Systems (TODS), Vol. 42, Issue 1, pages 1:1-1:46, March 2017.
		  </p></li>
	    </ul>
	    <h4>Patents</h4>
	    <ul>
	      <li><p>
		  <strong>Efficient training of neural networks</strong><br>
		  Dan Alistarh, Jerry Li, Ryota Tomioka, Milan Vojnovic<br>
		  </p></li>
	    </ul>
	    <h4>Other Writing</h4>
		<ul>
	      <li><p>
		  <a href="papers/mcm.pdf"><strong>Tracking Serial Criminals with a Road Metric</strong></a><br>
		  Mark Bun, Jerry Li, Ian Zemke. <br>
		  Our 2010 MCM submission, which was awarded an Outstanding Winner prize (the top prize).<br>
		  </p></li>
	    </ul>
	  </section>
	  <section id="talks">
	    <h3>Talks</h3>
	    <ul>
	    <li><p>
	    	<strong>Quantum Entropy Scoring for Fast Robust Mean Estimation and Improved Outlier Detection</strong><br>
	    	<ul>
	    		<li><p>Columbia Theory Seminar, July 2019</p></li>
	    	</ul>
	    </p></li>
	    <li><p>
	    	<strong>Efficiently Learning from Untrusted Batches</strong><br>
	    	<ul>
	    		<li><p>NYU Computation, Information, and Mathematics Seminar, July 2019</p></li>
	    	</ul>
	    </p></li>
	    <li><p>
	    	<strong>The Sample Complexity of Toeplitz Covariance Estimation</strong><br>
	    	<ul>
	    		<li><p>MIT Algorithms and Complexity Seminar, May 2019</p></li>
	    	</ul>
	    </p></li>
	    <li><p>
	    	<strong>Efficient Algorithms for High Dimensional Robust Learning</strong><br>
	    	<ul>
	    		<li><p>MSR AI Seminar, April 2019</p></li>
	    	</ul>
	    </p></li>
	    <li><p>
	    	<strong>Nearly Optimal Algorithms for Robust Mean Estimation</strong><br>
	    	<ul>
	    		<li><p>MIT Algorithms and Complexity Seminar, February 2019</p></li>
	    		<li><p>TTIC Machine Learning Seminar, February 2019<br></p></li>
	    		<li><p>MSR MLO Lunch, January 2019<br></p></li>
	    		<li><p>UW Theory Seminar, January 2019<br></p></li>
	    	</ul>
	    </p></li>
	    <li><p>
		  <strong>"Explicitly" Learning Mixtures of Gaussians</strong><br>
		  <ul>
		    <li><p>Simons Fellows Reading Group, September 2018<br></p></li>
		  </ul>

	      <li><p>
		  <strong>Robustly Learning a Gaussian in High Dimensions: Getting Optimal Error, Efficiently</strong><br>
		  <ul>
		    <li><p>SODA 2018, January 2018 <br></p></li>
		  </ul>
	      </p></li>
	      <li><p>
		  <strong>Mixture Models, Robustness, and Sum-of-Squares Proofs</strong><br>
		  <ul>
		  	<li><p>Google Algorithms Reading Group, July 2018<br></p></li>
		    <li><p>Microsoft Research Redmond, December 2017<br></p></li>
		    <li><p>MIT Algorithms and Complexity Semniar, November 2017<br></p></li>
		  </ul>
	      </p></li>
	      <li><p>
		  <strong>QSGD: Communication-Efficient SGD via Gradient Quantization and Encoding</strong><br>
		  <ul>
		    <li><p>NIPS 2017, December 2017 <br></p></li>
		  </ul>
	      </p></li>
	      <li><p>
		  <strong>Being Robust (in High Dimensions) can be Practical</strong><br>
		  <ul>
		    <li><p>ICML 2017, August 2017 <br></p></li>
		  </ul>
	      </p></li>
	      <li><p>
  		  <strong>Robust Proper Learning for Mixtures of Gaussians via Systems of Polynomial Inequalities</strong><br>
		  <ul>
		    <li><p>COLT 2017, July 2017 <br></p></li>
		  </ul>
		</p>
	      </li>
	      <li><p>
 		  <strong>Efficient Robust Sparse Estimation in High Dimensions</strong><br>
		  <ul>
		    <li><p>COLT 2017, July 2017. Joint with Simon Du<br></p></li>
		  </ul>
		</p>
	      </li>
 	      <li><p>
		<strong>Robust Estimators In High Dimensions without the Computational Intractability</strong> <a href="talks/robust-gaussian.pdf">[slides]</a><br>
		<ul>
		  <li><p>TCS+, December 2016 <a href="https://sites.google.com/site/plustcs/past-talks/20161207jerrylimit">[video]</a><br></p>
		  </li>
		  <li><p>FOCS, October 2016 <a href="http://techtalks.tv/talks/robust-estimators-in-high-dimensions-without-the-computational-intractability/62973/">[video]</a><br></p>
		  <li><p>ETH Theory Seminar, August 2016<br></p></li>
		  <li><p>UW Theory Lunch, July 2016<br></p></li>
 		  <li><p>MIT Algorithms and Complexity Seminar, June 2016<br></p></li>
		</ul>
 		</p>
 	      </li>
	      <li><p>
 		  <strong>Quantized Stochastic Gradient Descent</strong><br>
		  <ul>
		    <li><p>MIT ML Tea, October 2016<br></p></li>
		  </ul>
		</p>
	      </li>
 	      <li><p>
 		  <strong>Fast Algorithms for Segmented Regression</strong> <a href="talks/piecewise.pdf">[slides]</a><br>
		  <ul>
		  <li><p>ICML 2016 <a href="http://techtalks.tv/talks/fast-algorithms-for-segmented-regression/62543/">[video]</a><br></p></li>
		  </ul>
		  </p>
		</li>
	      <li><p>
		<strong>Fast and Near-Optimal Algorithms for Approximating Distributions by Histograms</strong> <a href="talks/pods15-presentation.pdf">[slides]</a><br>
		<ul>
		  <li><p>PODS 2015<br></p></li>
		</ul>
		</p>
	      </li>
	      <li><p>
		<strong>Model Counting of Query Expressions: Limitations of Propositional Methods</strong> <a href="talks/ICDT2014-FBDD.pptx">[slides]</a><br>
		<ul>
		  <li><p>ICDT 2015<br></p></li>
		  <li><p>MIT Theory Lunch, 2014<br></p></li>
		</ul>
		</p>
	      </li>
	    </ul>
	  </section>

	  <section id="misc">
	     <h3>Misc</h3>
	     <ul>
	       <li><p>
	     I'm participating in <a href="http://web.mit.edu/algoh/www/">Algorithms Office Hours</a>. If you're affiliated with MIT, and have algorithmic questions, please contact us!<br>
	     </p></li>
	       <li><p>
	     I am on the steering committee for <a href="http://www.slogn.org">SLOGN</a>*<br>
	     </p></li>
	       <li><p>
	     I organized the <a href="http://www.mit.edu/~pritish/theory_lunch/index.html">Great Ideas in Theoretical Computer Science</a> (aka theory lunch) in the 2013-2014 academic year.<br>
	     </p></li>
	       <li><p>
	     I stole the boombox from the <a href="http://gloriousoffice.com">Glorious Office</a> 3 times, then promptly lost it back each time.<br>
	     </p></li>
	     </ul>

	     <font size="1">* This might be false</font>
	  </section>
	</div>
      </div>
    </div><!-- /.container -->



    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-78178749-1', 'auto');
      ga('send', 'pageview');

    </script>
    <script type="text/javascript" src="https://code.jquery.com/jquery-1.11.3.min.js"></script>
    <script type="text/javascript" src="/static/tracking.js"></script>

    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="../../dist/js/bootstrap.min.js"></script>
    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <script src="../../assets/js/ie10-viewport-bug-workaround.js"></script>
  </body>
</html>
