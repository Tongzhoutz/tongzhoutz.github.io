<h2>Webpage for Econometrics (AS.180.633 2020 Spring)</h2>

<b>Instructor:</b> <a href="yhu@jhu.edu">Yingyao Hu</a> <br>
<b>TA:</b> Tong Zhou<br>
<b>Lectures:</b> Wed 10:00--12pm (Wyman 603)<br>
<b>Office Hours:</b> by appointment<br>
<br>
Syllabus: <a href="syllabus.pdf">link</a><br>
<br>

<h3>Prerequisites</h3>
No formal requirements, but this class will be fast-paced and assume mathematical maturity.

<h3>Lecture Notes</h3>

Updated periodically: <a href="notes.pdf">link</a> (last update 11/21/2019)<br>
<br>
Please e-mail typos/corrections to me (jsteinhardt@berkeley with a dot edu at the end).<br>
<br>See <a href="notes/">here</a> if you prefer notes broken up on a per-lecture basis.

<h3>Suggested Solutions</h3>

<a href="course/Econometrics_2020/hw_1_sol.pdf">Homework 1 Solution</a> <br>
<a href="course/Econometrics_2020/hw_2_sol.pdf">Homework 1 Solution</a> <br>
<a href="course/Econometrics_2020/hw_3_sol.pdf">Homework 3 Solution</a> <br>
<a href="course/Econometrics_2020/hw_4_sol.pdf">Homework 4 Solution</a> <br>
<a href="course/Econometrics_2020/hw_5_sol.pdf">Homework 5 Solution</a> <br>
<a href="course/Econometrics_2020/hw_6_sol.pdf">Homework 6 Solution</a> <br>
<a href="course/Econometrics_2020/hw_7_sol.pdf">Homework 7 Solution</a> <br>
<a href="course/Econometrics_2020/hw_8_sol.pdf">Homework 8 Solution</a> <br>
<a href="course/Econometrics_2020/hw_9_sol.pdf">Homework 9 Solution</a> 

<h3>Schedule</h3>

Lecture 1: Overview and 1D Robust Estimation (<a href="https://forms.gle/GWFnBvUMQccMerVc6">Feedback form</a>)<br>
Lecture 2: Minimum Distance Functionals and Resilience (<a href="https://forms.gle/VXiyevaxKTmSP1x59">Feedback form</a>)<br>
Lecture 3: Concentration Inequalities (<a href="https://forms.gle/x1f3oAGChHnQ88TD7">Feedback form</a>)<br>
Lecture 4: Bounding Suprema via Concentration Inequalities (<a href="https://forms.gle/Mr1vuArPwCGNR4eu6">Feedback form</a>)<br>
Lecture 5: Finite-Sample Analysis via Generalized KS Distance (<a href="https://forms.gle/XtDQYWLNCyF2kCDw8">Feedback form</a>)<br>
Lecture 6: Finite-Sample Analysis via Expanding the Destination Set (<a href="https://forms.gle/TSHhtV62uh8gr7Qm8">Feedback form</a>)<br>
Lecture 7: Truncated Moments and Ledoux-Talagrand (<a href="https://forms.gle/j6K1RvZhAN4nyudp8">Feedback form</a>)<br>
Lecture 8: Efficient Algorithms: Projecting onto Maximum Eigenvector (<a href="https://forms.gle/L5iWjGzNQi78Lcf56">Feedback form</a>)<br>
Lecture 9: Approximation Oracles and Grothendieck's Inequality (<a href="https://forms.gle/gyT1BxFDAsXFnqBz6">Feedback form</a>)<br>
Lecture 10: Semidefinite Programming and Sum-of-Squares (<a href="https://forms.gle/JcJujuxcjgSV1Jsr6">Feedback form</a>)<br>
Lecture 11: Sum-of-Squares and Poincar&#233; inequality (<a href="https://forms.gle/vNnaDTzsHj2jRjr48">Feedback form</a>)<br>
Lecture 12: Resilience Beyond Mean Estimation (<a href="https://forms.gle/UUWtQsVR78cMtYCG8">Feedback form</a>)<br>
Lecture 13: Resilience For Linear Regression<br>
Lecture 14: Efficient Algorithms for Linear Regression<br>
Lecture 15: Resilience for Wasserstein Distances<br>
Lecture 16: Wasserstein Resilience for Moment Estimation and Linear Regression<br>
Lecture 17: Test-Time Robustness<br>
Lecture 18: Adversarial Training and Certified Robustness<br>
Lecture 19: Randomized Smoothing<br>
Lecture 20: Domain Adaptation under Covariate Shift<br>
Lecture 21: Doubly-Robust Estimators and Semi-Parametric Estimation<br>
Lecture 22: Partial Specification for Linear Regression<br>
Lecture 23: Partial Specification and Agnostic Clustering<br>
Lecture 24: Agnostic Clustering via Resilience<br>
Lecture 25: Efficient Clustering via SVD + k-means<br>
Lecture 26: Transfer Learning via Dimensionality Reduction<br>
Lecture 27: TBD<br>

<br>
<a href="https://forms.gle/uyVganPfVk58Mx3Q9">Feedback form</a> for Lecture 13 onwards.

<h3>Supplementary Reading List</h3>

Jerry Li is teaching a <a href="https://jerryzli.github.io/robust-ml-fall19.html">class</a> on similar topics.<br>
<br>
<a href="https://www.stat.berkeley.edu/~jsteinhardt/pubs/steinhardt2018thesis.pdf">Robust Learning: Information Theory and Algorithms</a> (Jacob Steinhardt's thesis)<br>
<a href="https://terrytao.wordpress.com/2010/01/03/254a-notes-1-concentration-of-measure/">Concentration of Measure</a> (lecture notes by Terence Tao)<br>
<li>Alternate reference: <a href="http://www.econ.upf.edu/~lugosi/mlss_conc.pdf">Concentration Inequalities</a> (notes by Boucheron, Lugosi, and Bousquet)<br>
<a href="https://arxiv.org/abs/1909.08755">Generalized Resilience and Robust Statistics</a> (Zhu, Jiao, Steinhardt)<br>
<a href="https://jerryzli.github.io/papers/phd-thesis.pdf">Principled Approaches to Robust Machine Learning and Beyond</a> (Jerry Li's thesis)<br>
<a href="https://stanford.edu/~jduchi/projects/probability_bounds.pdf">Probability Bounds</a> (John Duchi; contains exposition on Ledoux-Talagrand)<br>
<a href="https://web.math.princeton.edu/~naor/homepage%20files/cutnorm.pdf">Approximating the Cut-Norm via Grothendieck's Inequality</a> (Alon and Naor)<br>
<a href="https://arxiv.org/abs/1711.07465">Better Agnostic Clustering via Relaxed Tensor Norms</a> (Kothari and Steinhardt)<br>
<a href="https://arxiv.org/abs/math/0701886">Ricci curvature of Markov chains on metric spaces</a> (Ollivier; relation between Poincar&#233; inequalities and Markov chain convergence)<br>
<i>Concentration inequalities: A nonasymptotic theory of independence</i> (Boucheron, Lugosi, and Massart; good general survey that contains discussion of Poincar&#233; inequalities)<br>
<a href="https://arxiv.org/abs/1711.00851">Provable Defenses against Adversarial Examples via the Convex Outer Adversarial Polytope</a> (Eric Wong and Zico Kolter)<br>
<a href="https://arxiv.org/abs/1805.10265">Training Verified Learners with Learned Verifiers</a> (Krishnamurthy Dvijotham et al.)<br>
<a href="https://arxiv.org/abs/1811.01057">Semidefinite relaxations for certifying robustness to adversarial examples</a> (Aditi Raghunathan et al.)

